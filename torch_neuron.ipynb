{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6529310",
   "metadata": {},
   "source": [
    "## Download and unzip pretrained model, and put into directory pretrained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aefaa811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gdown\n",
    "# !gdown https://drive.google.com/u/0/uc?id=1FqwAzeqZcegcskpjr3ZmeA9X-oQxPLmK&export=download    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e42489",
   "metadata": {},
   "source": [
    "## Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff7e8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from Source.models.RectificationBaseline import ModelBuilder\n",
    "model = ModelBuilder(\n",
    "    arch=\"ResNet_FPN\",\n",
    "    rec_num_classes=90,\n",
    "    sDim=256,\n",
    "    attDim=256,\n",
    "    max_len_labels=20,\n",
    "    REC_ON=True,\n",
    "    FEAT_FUSE=False,\n",
    "    tps_margins=tuple([0.0, 0.0]),\n",
    "    STN_ON=True,\n",
    ")\n",
    "\n",
    "local_model_path = os.path.join(\"pretrained_models\", \"Real_15.pth.tar\")\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     Pku = Pku.to(torch.device(\"cuda\"))\n",
    "#     logging.error(\"gpu is available, switching to CUDA\")\n",
    "#     checkpoint = torch.load(local_model_path)\n",
    "# else:\n",
    "#     checkpoint = torch.load(local_model_path, map_location=\"cpu\")\n",
    "checkpoint = torch.load(local_model_path, map_location=\"cpu\")\n",
    "\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e12676",
   "metadata": {},
   "source": [
    "## Read Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecc10b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "orig_image = Image.open(\"imgs/temp.png\").convert('RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73b5221",
   "metadata": {},
   "source": [
    "## Transform Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "062708c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.asarray(orig_image)\n",
    "image = cv2.resize(image, (256, 64)).astype(np.float64)\n",
    "image = (image - 128.0) / 128.0  # (img - mean) / std. [-1, 1]\n",
    "image = np.transpose(image, (2, 0, 1))\n",
    "image = torch.from_numpy(image).float().unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55aae2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/inferentia/lib/python3.6/site-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/inferentia/lib/python3.6/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/inferentia/lib/python3.6/site-packages/torch/nn/functional.py:3829: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  \"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    }
   ],
   "source": [
    "output_dict = model.forward(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "685c0ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Source.evaluation_metrics.metrics import get_str\n",
    "output = get_str(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab47a1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=369x137 at 0x7F16E7038128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text']\n"
     ]
    }
   ],
   "source": [
    "display(orig_image)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e68e05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f3af743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1.1.4.1.0\n"
     ]
    }
   ],
   "source": [
    "import torch_neuron\n",
    "print(torch_neuron.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02a2def4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 64, 256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62830130",
   "metadata": {},
   "source": [
    "## Torch neuron analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92ba1571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/Source/models/tps_spatial_transformer.py:119: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert source_control_points.size(1) == self.num_control_points\n",
      "/home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/Source/models/tps_spatial_transformer.py:120: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert source_control_points.size(2) == 2\n",
      "INFO:Neuron:The following operations are currently supported in torch-neuron for this model:\n",
      "INFO:Neuron:aten::batch_norm\n",
      "INFO:Neuron:aten::add\n",
      "INFO:Neuron:aten::addmm\n",
      "INFO:Neuron:aten::matmul\n",
      "INFO:Neuron:aten::mul\n",
      "INFO:Neuron:aten::squeeze\n",
      "INFO:Neuron:aten::size\n",
      "INFO:Neuron:prim::ListConstruct\n",
      "INFO:Neuron:aten::to\n",
      "INFO:Neuron:aten::sub\n",
      "INFO:Neuron:aten::bmm\n",
      "INFO:Neuron:aten::transpose\n",
      "INFO:Neuron:aten::cat\n",
      "INFO:Neuron:aten::zeros\n",
      "INFO:Neuron:aten::tanh\n",
      "INFO:Neuron:aten::_convolution\n",
      "INFO:Neuron:prim::TupleConstruct\n",
      "INFO:Neuron:aten::view\n",
      "INFO:Neuron:aten::clamp\n",
      "INFO:Neuron:aten::relu\n",
      "INFO:Neuron:aten::fill_\n",
      "INFO:Neuron:aten::sigmoid\n",
      "INFO:Neuron:aten::expand\n",
      "INFO:Neuron:aten::unsqueeze\n",
      "INFO:Neuron:aten::t\n",
      "INFO:Neuron:prim::NumToTensor\n",
      "INFO:Neuron:aten::Int\n",
      "INFO:Neuron:aten::max\n",
      "INFO:Neuron:prim::TupleUnpack\n",
      "INFO:Neuron:aten::max_pool2d\n",
      "INFO:Neuron:aten::upsample_bilinear2d\n",
      "INFO:Neuron:aten::contiguous\n",
      "INFO:Neuron:aten::softmax\n",
      "INFO:Neuron:prim::Constant\n",
      "INFO:Neuron:The following operations are currently not supported in torch-neuron for this model:\n",
      "INFO:Neuron:aten::embedding\n",
      "INFO:Neuron:aten::grid_sampler\n",
      "INFO:Neuron:aten::gru\n",
      "INFO:Neuron:aten::lstm\n",
      "INFO:Neuron:99.12% of all operations (including primitives) (4712 of 4754) are supported\n",
      "INFO:Neuron:96.01% of arithmetic operations (1010 of 1052) are supported\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('percent_supported', 99.11653344551956),\n",
       "             ('percent_supported_arithmetic', 96.00760456273764),\n",
       "             ('supported_count', 4712),\n",
       "             ('total_count', 4754),\n",
       "             ('supported_count_arithmetic', 1010),\n",
       "             ('total_count_arithmetic', 1052),\n",
       "             ('supported_operators',\n",
       "              {'aten::Int',\n",
       "               'aten::_convolution',\n",
       "               'aten::add',\n",
       "               'aten::addmm',\n",
       "               'aten::batch_norm',\n",
       "               'aten::bmm',\n",
       "               'aten::cat',\n",
       "               'aten::clamp',\n",
       "               'aten::contiguous',\n",
       "               'aten::expand',\n",
       "               'aten::fill_',\n",
       "               'aten::matmul',\n",
       "               'aten::max',\n",
       "               'aten::max_pool2d',\n",
       "               'aten::mul',\n",
       "               'aten::relu',\n",
       "               'aten::sigmoid',\n",
       "               'aten::size',\n",
       "               'aten::softmax',\n",
       "               'aten::squeeze',\n",
       "               'aten::sub',\n",
       "               'aten::t',\n",
       "               'aten::tanh',\n",
       "               'aten::to',\n",
       "               'aten::transpose',\n",
       "               'aten::unsqueeze',\n",
       "               'aten::upsample_bilinear2d',\n",
       "               'aten::view',\n",
       "               'aten::zeros',\n",
       "               'prim::Constant',\n",
       "               'prim::ListConstruct',\n",
       "               'prim::NumToTensor',\n",
       "               'prim::TupleConstruct',\n",
       "               'prim::TupleUnpack'}),\n",
       "             ('unsupported_operators',\n",
       "              ['aten::embedding',\n",
       "               'aten::grid_sampler',\n",
       "               'aten::gru',\n",
       "               'aten::lstm']),\n",
       "             ('operators',\n",
       "              ['aten::Int',\n",
       "               'aten::_convolution',\n",
       "               'aten::add',\n",
       "               'aten::addmm',\n",
       "               'aten::batch_norm',\n",
       "               'aten::bmm',\n",
       "               'aten::cat',\n",
       "               'aten::clamp',\n",
       "               'aten::contiguous',\n",
       "               'aten::embedding',\n",
       "               'aten::expand',\n",
       "               'aten::fill_',\n",
       "               'aten::grid_sampler',\n",
       "               'aten::gru',\n",
       "               'aten::lstm',\n",
       "               'aten::matmul',\n",
       "               'aten::max',\n",
       "               'aten::max_pool2d',\n",
       "               'aten::mul',\n",
       "               'aten::relu',\n",
       "               'aten::sigmoid',\n",
       "               'aten::size',\n",
       "               'aten::softmax',\n",
       "               'aten::squeeze',\n",
       "               'aten::sub',\n",
       "               'aten::t',\n",
       "               'aten::tanh',\n",
       "               'aten::to',\n",
       "               'aten::transpose',\n",
       "               'aten::unsqueeze',\n",
       "               'aten::upsample_bilinear2d',\n",
       "               'aten::view',\n",
       "               'aten::zeros',\n",
       "               'prim::Constant',\n",
       "               'prim::ListConstruct',\n",
       "               'prim::NumToTensor',\n",
       "               'prim::TupleConstruct',\n",
       "               'prim::TupleUnpack']),\n",
       "             ('operator_count',\n",
       "              OrderedDict([('aten::Int', 132),\n",
       "                           ('aten::_convolution', 70),\n",
       "                           ('aten::add', 39),\n",
       "                           ('aten::addmm', 82),\n",
       "                           ('aten::batch_norm', 64),\n",
       "                           ('aten::bmm', 20),\n",
       "                           ('aten::cat', 22),\n",
       "                           ('aten::clamp', 1),\n",
       "                           ('aten::contiguous', 1),\n",
       "                           ('aten::embedding', 20),\n",
       "                           ('aten::expand', 21),\n",
       "                           ('aten::fill_', 1),\n",
       "                           ('aten::grid_sampler', 1),\n",
       "                           ('aten::gru', 20),\n",
       "                           ('aten::lstm', 1),\n",
       "                           ('aten::matmul', 2),\n",
       "                           ('aten::max', 20),\n",
       "                           ('aten::max_pool2d', 7),\n",
       "                           ('aten::mul', 1),\n",
       "                           ('aten::relu', 60),\n",
       "                           ('aten::sigmoid', 1),\n",
       "                           ('aten::size', 50),\n",
       "                           ('aten::softmax', 40),\n",
       "                           ('aten::squeeze', 61),\n",
       "                           ('aten::sub', 1),\n",
       "                           ('aten::t', 82),\n",
       "                           ('aten::tanh', 20),\n",
       "                           ('aten::to', 41),\n",
       "                           ('aten::transpose', 1),\n",
       "                           ('aten::unsqueeze', 80),\n",
       "                           ('aten::upsample_bilinear2d', 3),\n",
       "                           ('aten::view', 83),\n",
       "                           ('aten::zeros', 4),\n",
       "                           ('prim::Constant', 3110),\n",
       "                           ('prim::ListConstruct', 463),\n",
       "                           ('prim::NumToTensor', 50),\n",
       "                           ('prim::TupleConstruct', 40),\n",
       "                           ('prim::TupleUnpack', 39)]))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze the model - this will show operator support and operator count\n",
    "torch.neuron.analyze_model(model, example_inputs=image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa59e98",
   "metadata": {},
   "source": [
    "## Torch neuron trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1750ad1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/inferentia/lib/python3.6/site-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/inferentia/lib/python3.6/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/Source/models/tps_spatial_transformer.py:119: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert source_control_points.size(1) == self.num_control_points\n",
      "/home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/Source/models/tps_spatial_transformer.py:120: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert source_control_points.size(2) == 2\n",
      "/inferentia/lib/python3.6/site-packages/torch/nn/functional.py:3829: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  \"Default grid_sample and affine_grid behavior has changed \"\n",
      "INFO:Neuron:There are 42 ops of 4 different types in the TorchScript that are not compiled by neuron-cc: aten::gru, aten::embedding, aten::lstm, aten::grid_sampler, (For more information see https://github.com/aws/aws-neuron-sdk/blob/master/release-notes/neuron-cc-ops/neuron-cc-ops-pytorch.md)\n",
      "INFO:Neuron:Number of arithmetic operators (pre-compilation) before = 1052, fused = 1010, percent fused = 96.01%\n",
      "INFO:Neuron:Compiling function _NeuronGraph$3818 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/0/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/0/graph_def.neff --io-config {\"inputs\": {\"0:0\": [[1, 3, 64, 256], \"float32\"]}, \"outputs\": [\"transpose_293:0\", \"Sub_57:0\"]} --verbose 1'\n",
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3818; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/0/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/0/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[1, 3, 64, 256], \"float32\"]}, \"outputs\": [\"transpose_293:0\", \"Sub_57:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/0/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/0/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[1, 3, 64, 256], \"float32\"]}, \"outputs\": [\"transpose_293:0\", \"Sub_57:0\"]}' --verbose 1\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3819; falling back to native python function call\n",
      "ERROR:Neuron:'numpy.ndarray' object has no attribute 'name'\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 126, in trace\n",
      "    '--io-config', _io_config(input_tensors, output_tensors)]\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 1097, in _io_config\n",
      "    outputs = [ts.name for ts in output_tensors]\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 1097, in <listcomp>\n",
      "    outputs = [ts.name for ts in output_tensors]\n",
      "AttributeError: 'numpy.ndarray' object has no attribute 'name'\n",
      "INFO:Neuron:Compiling function _NeuronGraph$3820 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/6/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/6/graph_def.neff --io-config {\"inputs\": {\"0:0\": [[1, 256, 16, 64], \"float32\"]}, \"outputs\": [\"transpose_41:0\", \"zeros:0\", \"zeros_1:0\"]} --verbose 1'\n",
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3820; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/6/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/6/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[1, 256, 16, 64], \"float32\"]}, \"outputs\": [\"transpose_41:0\", \"zeros:0\", \"zeros_1:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/6/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/6/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[1, 256, 16, 64], \"float32\"]}, \"outputs\": [\"transpose_41:0\", \"zeros:0\", \"zeros_1:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::zeros with inputs [[1, <tf.Tensor 'strided_slice:0' shape=() dtype=int32>, 256], 6, 0, device(type='cpu'), False]\n",
      "INFO:Neuron:Exception = List of Tensors when single Tensor expected\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3821; falling back to native python function call\n",
      "ERROR:Neuron:List of Tensors when single Tensor expected\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py\", line 324, in _AssertCompatible\n",
      "    fn(values)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py\", line 276, in _check_not_tensor\n",
      "    _ = [_check_failed(v) for v in nest.flatten(values)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py\", line 277, in <listcomp>\n",
      "    if isinstance(v, ops.Tensor)]\n",
      "  File \"/inferentia/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py\", line 248, in _check_failed\n",
      "    raise ValueError(v)\n",
      "ValueError: Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 1668, in zeros\n",
      "    shape = tf.constant(shape)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\", line 161, in constant_v1\n",
      "    allow_broadcast=False)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\", line 265, in _constant_impl\n",
      "    allow_broadcast=allow_broadcast))\n",
      "  File \"/inferentia/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py\", line 449, in make_tensor_proto\n",
      "    _AssertCompatible(values, dtype)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py\", line 328, in _AssertCompatible\n",
      "    raise TypeError(\"List of Tensors when single Tensor expected\")\n",
      "TypeError: List of Tensors when single Tensor expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3822; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$3823 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/329/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/329/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n",
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3823; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/329/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/329/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/329/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/329/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3824; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$3825 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/333/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/333/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n",
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3825; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/333/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/333/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/333/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/333/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3826; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "INFO:Neuron:Compiling function _NeuronGraph$3827 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/337/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/337/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3827; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/337/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/337/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/337/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/337/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3828; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$3829 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/341/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/341/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n",
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3829; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/341/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/341/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/341/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/341/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3830; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$3831 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/345/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/345/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n",
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3831; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/345/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/345/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/345/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/345/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3832; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$3833 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/349/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/349/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n",
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3833; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/349/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/349/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/349/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/349/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3834; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$3835 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/353/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/353/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n",
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3835; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/353/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/353/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/353/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/353/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3836; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$3837 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/357/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/357/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n",
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3837; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/357/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/357/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/357/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/357/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3838; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "INFO:Neuron:Compiling function _NeuronGraph$3839 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/361/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/361/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3839; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/361/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/361/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/361/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/361/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3840; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$3841 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/365/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/365/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n",
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3841; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/365/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/365/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/365/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/365/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3842; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$3843 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/369/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/369/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n",
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3843; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/369/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/369/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/369/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/369/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3844; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "INFO:Neuron:Compiling function _NeuronGraph$3845 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/373/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/373/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3845; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/373/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/373/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/373/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/373/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3846; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "INFO:Neuron:Compiling function _NeuronGraph$3847 with neuron-cc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/377/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/377/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n",
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3847; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/377/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/377/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/377/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/377/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3848; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "INFO:Neuron:Compiling function _NeuronGraph$3849 with neuron-cc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/381/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/381/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n",
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3849; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/381/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/381/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/381/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/381/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3850; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "INFO:Neuron:Compiling function _NeuronGraph$3851 with neuron-cc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/385/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/385/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n",
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3851; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/385/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/385/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/385/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/385/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3852; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$3853 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/389/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/389/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n",
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3853; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/389/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/389/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/389/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/389/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3854; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "INFO:Neuron:Compiling function _NeuronGraph$3855 with neuron-cc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/393/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/393/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n",
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3855; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/393/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/393/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/393/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/393/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3856; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "INFO:Neuron:Compiling function _NeuronGraph$3857 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/397/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/397/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3857; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/397/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/397/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/397/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/397/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "INFO:Neuron:PyTorch to TF conversion failed to resolve function on aten::max with inputs [<tf.Tensor 'Softmax:0' shape=(1, 90) dtype=float32>, 1, False]\n",
      "INFO:Neuron:Exception = Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3858; falling back to native python function call\n",
      "ERROR:Neuron:Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 79, in trace\n",
      "    transform_torch_graph_to_tensorflow(jit_trace, example_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 487, in transform_torch_graph_to_tensorflow\n",
      "    raise e\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 481, in transform_torch_graph_to_tensorflow\n",
      "    tensor_outputs = local_func(op, *tensor_inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 886, in max\n",
      "    return max_other(op, *args)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py\", line 855, in max_other\n",
      "    raise NotImplementedError(failure_context())\n",
      "NotImplementedError: Operator translation failed in /inferentia/lib/python3.6/site-packages/torch_neuron/ops/aten.py:855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::max is not supported in torch-neuron for two tensor variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$3859 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/401/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/401/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]} --verbose 1'\n",
      "INFO:Neuron:Compile command returned: 120\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3859; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/401/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/401/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 191, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/inferentia/bin/neuron-cc compile /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/401/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/DATA/raghav/inferentia/ICDAR2019-ArT-Recognition-Alchemy/neuron_compile/401/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[1, 31, 512], \"float32\"], \"1:0\": [[1, 1, 256], \"float32\"], \"2:0\": [[1, 256], \"float32\"]}, \"outputs\": [\"ExpandDims_2:0\"]}' --verbose 1\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$3860; falling back to native python function call\n",
      "ERROR:Neuron:softmax() received an invalid combination of arguments - got (dtype=NoneType, input=tuple, dim=int, ), but expected one of:\n",
      " * (Tensor input, name dim, *, torch.dtype dtype)\n",
      " * (Tensor input, int dim, torch.dtype dtype)\n",
      "      didn't match because some of the arguments have invalid types: (!input=tuple!, dim=int, !dtype=NoneType!, )\n",
      "Traceback (most recent call last):\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\", line 330, in op_converter\n",
      "    dynamic_batch_size=self.dynamic_batch_size, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 76, in trace\n",
      "    jit_trace = jit_trace_function(func, example_inputs, args, kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/decorators.py\", line 401, in jit_trace_function\n",
      "    jit_trace = torch.jit.trace(func, example_inputs, *args, **kwargs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch/jit/_trace.py\", line 779, in trace\n",
      "    name, func, example_inputs, var_lookup_fn, strict, _force_outplace\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/graph.py\", line 178, in __call__\n",
      "    self.run_op(op, unique_tensor_map, op_converter)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/graph.py\", line 189, in run_op\n",
      "    outputs = op(*inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/graph.py\", line 306, in __call__\n",
      "    return self.func(self, *inputs)\n",
      "  File \"/inferentia/lib/python3.6/site-packages/torch_neuron/resolve_function.py\", line 55, in func\n",
      "    return auto_func(**_get_kwargs(op, func_args, args))\n",
      "TypeError: softmax() received an invalid combination of arguments - got (dtype=NoneType, input=tuple, dim=int, ), but expected one of:\n",
      " * (Tensor input, name dim, *, torch.dtype dtype)\n",
      " * (Tensor input, int dim, torch.dtype dtype)\n",
      "      didn't match because some of the arguments have invalid types: (!input=tuple!, dim=int, !dtype=NoneType!, )\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "softmax() received an invalid combination of arguments - got (dtype=NoneType, input=tuple, dim=int, ), but expected one of:\n * (Tensor input, name dim, *, torch.dtype dtype)\n * (Tensor input, int dim, torch.dtype dtype)\n      didn't match because some of the arguments have invalid types: (!input=tuple!, dim=int, !dtype=NoneType!, )\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bc81eaa0e07c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_neuron = torch.neuron.trace(model, example_inputs=image, \n\u001b[1;32m      2\u001b[0m                                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                   compiler_workdir='neuron_compile')\n\u001b[0m",
      "\u001b[0;32m/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, fallback, op_whitelist, minimum_segment_size, subgraph_builder_function, subgraph_inputs_pruning, skip_compiler, debug_must_trace, allow_no_ops_on_neuron, compiler_workdir, dynamic_batch_size, _neuron_trace, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjit_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mskip_inference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mneuron_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_fused_operators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0mcu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_post_compiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/inferentia/lib/python3.6/site-packages/torch_neuron/convert.py\u001b[0m in \u001b[0;36mcompile_fused_operators\u001b[0;34m(self, neuron_graph, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;31m# STEP 2: Invoke the graphs, passing an \"op_converter\" or compiler functor to be invoked on each subgraph - mutate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mneuron_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mneuron_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_converter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop_converter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;31m# STEP 3: (re)Import the compiled sub-graphs as fused neuron operators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/inferentia/lib/python3.6/site-packages/torch_neuron/graph.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, op_converter, *inputs)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0munique_tensor_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_tensor_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_converter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_name_to_free_uniques\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0munique\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_name_to_free_uniques\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/inferentia/lib/python3.6/site-packages/torch_neuron/graph.py\u001b[0m in \u001b[0;36mrun_op\u001b[0;34m(self, op, unique_tensor_map, op_converter)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mop_converter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_uniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/inferentia/lib/python3.6/site-packages/torch_neuron/graph.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, op_converter, *inputs)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0munique_tensor_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_tensor_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_converter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_name_to_free_uniques\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0munique\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_name_to_free_uniques\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/inferentia/lib/python3.6/site-packages/torch_neuron/graph.py\u001b[0m in \u001b[0;36mrun_op\u001b[0;34m(self, op, unique_tensor_map, op_converter)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mop_converter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_uniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/inferentia/lib/python3.6/site-packages/torch_neuron/graph.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/inferentia/lib/python3.6/site-packages/torch_neuron/resolve_function.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(op, *args)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mauto_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_get_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: softmax() received an invalid combination of arguments - got (dtype=NoneType, input=tuple, dim=int, ), but expected one of:\n * (Tensor input, name dim, *, torch.dtype dtype)\n * (Tensor input, int dim, torch.dtype dtype)\n      didn't match because some of the arguments have invalid types: (!input=tuple!, dim=int, !dtype=NoneType!, )\n"
     ]
    }
   ],
   "source": [
    "model_neuron = torch.neuron.trace(model, example_inputs=image, \n",
    "                                  verbose=1,\n",
    "                                  compiler_workdir='neuron_compile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c4f09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
